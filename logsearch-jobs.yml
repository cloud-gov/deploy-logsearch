instance_groups:
#######################################################
#First deploy group - elasticsearch_master, maintenance
#######################################################
- name: elasticsearch_master
  instances: 3
  jobs:
  - name: elasticsearch
    release: logsearch
    provides:
      elasticsearch: {as: elasticsearch_master}
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        cluster_name: logsearch
        migrate_data_path: true
        node:
          allow_master: true
          allow_data: false
        exec:
          environment:
            JAVA_OPTS: '"-Djava.io.tmpdir=${TMP_DIR}"'
        limits:
          fd: 131072  # 2 ** 17
        health:
          timeout: 900
        recovery:
          delay_allocation_restart: "15m"
  - name: snort-config
    release: snort
    properties:
      snort:
        rules:
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"POST"; http_method; content: "logs-app"; http_uri; content:"/_update"; http_uri; classtype:web-application-attack; sid:343080002; rev:1;)'
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"POST"; http_method; content: "logs-platform"; http_uri; content:"/_update"; http_uri; classtype:web-application-attack; sid:343080003; rev:1;)'
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"DELETE"; http_method; content: "logs-app"; http_uri; classtype:web-application-attack; sid:343080004; rev:1;)'
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"DELETE"; http_method; content: "logs-platform"; http_uri; classtype:web-application-attack; sid:343080005; rev:1;)'
        - (( concat "suppress gen_id 1, sig_id 343080004, track by_src, ip " instance_groups.maintenance.networks.services.static_ips.[0] ))
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"DELETE"; http_method; content: "logs-platform"; http_uri; classtype:web-application-attack; sid:343080005; rev:1;)'
        - (( concat "suppress gen_id 1, sig_id 343080005, track by_src, ip " instance_groups.maintenance.networks.services.static_ips.[0] ))
  persistent_disk_type: logsearch_es_master
  stemcell: default
  azs: [z1]
  networks:
  - name: services
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[0]))
    - (( grab terraform_outputs.logsearch_static_ips.[1]))
    - (( grab terraform_outputs.logsearch_static_ips.[2]))
  vm_extensions: [logsearch-lb]
  update:
    max_in_flight: 1 # Should never update more than one ES master node at a time or cluster will go down

- name: redis
  instances: 1
  jobs:
  - {name: redis, release: logsearch-for-cloudfoundry}
  persistent_disk_type: logsearch_redis
  stemcell: default
  azs: [z1]
  networks:
  - name: services

- name: maintenance
  instances: 1
  vm_extensions: [errand-profile]
  jobs:
  - name: elasticsearch
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        migrate_data_path: true
  - name: curator
    release: logsearch
    # nil the link and use the colocated instance when https://github.com/cloudfoundry-community/logsearch-boshrelease/pull/90 is merged
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      curator:
        purge_logs:
          retention_period: 180
  - name: elasticsearch_config
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch_config:
        templates:
        - shards-and-replicas: /var/vcap/jobs/elasticsearch_config/index-templates/shards-and-replicas.json
        - index-settings: /var/vcap/jobs/elasticsearch_config/index-templates/index-settings.json
        - index-mappings: /var/vcap/jobs/elasticsearch_config/index-templates/index-mappings.json
        - index-mappings-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings.json
        - index-mappings-app-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings-app.json
        - index-mappings-platform-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings-platform.json
  - name: elasticsearch-config-lfc
    release: logsearch-for-cloudfoundry
  - name: elasticsearch_exporter
    release: prometheus
    properties:
      elasticsearch_exporter:
        es:
          uri: http://localhost:9200
          all: true
        elasticsearch_config:
          app_index_settings:
            index.mapping.total_fields.limit: 2000
  - name: upload-kibana-objects
    release: logsearch-for-cloudfoundry
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      cloudfoundry:
        firehose_events:
        - LogMessage
        - ContainerMetric
        system_domain: (( grab $CF_SYSTEM_DOMAIN ))
        user: (( grab $CF_USERNAME ))
        password: (( grab $CF_PASSWORD ))
      kibana_objects:
        upload_patterns:
        - {type: index-pattern, pattern: "/var/vcap/jobs/upload-kibana-objects/kibana-objects/index-pattern/*.json"}
        - {type: config, pattern: "/var/vcap/jobs/upload-kibana-objects/kibana-objects/config/*.json"}
        - {type: search, pattern: "/var/vcap/jobs/upload-kibana-objects/kibana-objects/search/app-*.json"}
        - {type: visualization, pattern: "/var/vcap/jobs/upload-kibana-objects/kibana-objects/visualization/App-*.json"}
        - {type: dashboard, pattern: "/var/vcap/jobs/upload-kibana-objects/kibana-objects/dashboard/App-*.json"}
  # TODO: Drop after https://github.com/cloudfoundry-community/logsearch-for-cloudfoundry/pull/267 is merged
  - name: cron
    release: cron
    properties:
      cron:
        entries:
        - script:
            name: slow-logs
            contents: (( file "cronjobs/slow-logs.sh" ))
          variables:
            HOST: (( grab instance_groups.elasticsearch_master.networks.services.static_ips.[0] ))
          minute: "0"
          hour: "0"
          day: "*"
          month: "*"
          wday: "*"
          user: root
  stemcell: default
  azs: [z1]
  networks:
  - name: services
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[5] ))
  update:
    serial: true # Block on this job to create deploy group 1

#########################################################
#2nd deploy group - elasticsearch_data, kibana, ingestors
#########################################################
- name: elasticsearch_data
  instances: 9
  jobs:
  - name: elasticsearch
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        node:
          allow_master: false
          allow_data: true
        exec:
          environment:
            JAVA_OPTS: '"-Djava.io.tmpdir=${TMP_DIR}"'
        limits:
          fd: 131072  # 2 ** 17
        health:
          timeout: 900
        recovery:
          delay_allocation_restart: "15m"
        migrate_data_path: true
  persistent_disk_type: logsearch_es_data
  stemcell: default
  azs: [z1]
  networks:
  - name: services
  update:
    max_in_flight: 1 # Only update 1 ES data node at a time or risk downtime

- name: kibana
  instances: 2
  jobs:
  - name: elasticsearch
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        heap_size: 2G
        migrate_data_path: true
  - name: kibana
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      kibana:
        memory_limit: 75
        default_app_id: "dashboard/App-Overview"
        plugins:
        - auth: /var/vcap/packages/kibana-auth-plugin/kibana-auth-plugin.zip
        config_options: 
          console.enabled: false
        env:
        - NODE_ENV: production
        source_files: [/var/vcap/jobs/kibana-auth-plugin/config/config.sh]
        health:
          timeout: 600
  - name: kibana-auth-plugin
    release: logsearch-for-cloudfoundry
    properties:
      kibana-auth:
        cloudfoundry:
          skip_ssl_validation: false
          client_id: kibana_oauth2_client
          system_org: cloud-gov-operators # Org Managers of this org get admin access
        session_key: (( param "specify kibana session key" ))
  - name: route_registrar
    release: cf
    properties:
      route_registrar:
        routes:
        - name: logsearch
          registration_interval: 2s
          port: 5601
          health_check:
            name: kibana-up
            script_path: /var/vcap/jobs/kibana/bin/post-start
          timeout: 1s
  stemcell: default
  azs: [z1]
  networks:
  - name: services

- name: archiver
  jobs:
  - name: elasticsearch
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        migrate_data_path: true
  - name: archiver_syslog
    release: logsearch
    properties:
      logstash:
        queue:
          max_bytes: 30gb
      logstash_archiver:
        files: 16384
      logstash_ingestor:
        outputs:
        - plugin: s3
          options:
            region: (( grab terraform_outputs.vpc_region ))
            bucket: (( grab terraform_outputs.logsearch_archive_bucket_name ))
            validate_credentials_on_root_bucket: false  # https://github.com/logstash-plugins/logstash-output-s3/issues/132
            server_side_encryption: true
            time_file: 5
            prefix: "%{+yyyy/MM/dd/HH/mm}"
            encoding: "gzip"
  - name: ingestor_cloudfoundry-firehose
    release: logsearch-for-cloudfoundry
    properties:
      cloudfoundry:
        firehose_subscription_id: logsearch-archiver
        firehose_events:
        - LogMessage
        - ContainerMetric
        firehose_client_id: logsearch_firehose_ingestor
        firehose_cc_pull_interval: 300s
        skip_ssl_validation: false
      syslog:
        host: 127.0.0.1
        port: 5514
  persistent_disk_type: logsearch_ingestor
  stemcell: default
  azs: [z1]
  networks:
  - name: services
  vm_extensions: [logsearch-ingestor-profile]

- name: ingestor
  jobs:
  - name: elasticsearch
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      elasticsearch:
        heap_size: 1G
        migrate_data_path: true
  - name: ingestor_syslog
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
    properties:
      logstash:
        queue:
          max_bytes: 30gb
      logstash_parser:
        elasticsearch:
          # Use per-day indexing strategy
          index: "logs-app-%{+YYYY.MM.dd}"
          index_type: "%{@type}"
          data_hosts: [127.0.0.1]
        filters:
        - logsearch-for-cf: /var/vcap/packages/logsearch-config-logstash-filters/logstash-filters-default.conf
        deployment_dictionary:
        - /var/vcap/packages/logsearch-config/deployment_lookup.yml
        - /var/vcap/jobs/parser-config-lfc/config/deployment_lookup.yml
  - name: ingestor_cloudfoundry-firehose
    release: logsearch-for-cloudfoundry
    properties:
      cloudfoundry:
        firehose_subscription_id: logsearch-ingestor
        firehose_events:
        - LogMessage
        - ContainerMetric
        firehose_client_id: logsearch_firehose_ingestor
        firehose_cc_pull_interval: 300s
        skip_ssl_validation: false
      syslog:
        host: 127.0.0.1
        port: 5514
  - name: parser-config-lfc
    release: logsearch-for-cloudfoundry
  persistent_disk_type: logsearch_ingestor
  stemcell: default
  azs: [z1]
  networks:
  - name: services

###########################
#3nd deploy group - errands
###########################
- name: smoke-tests
  instances: 1
  vm_extensions: [errand-profile]
  stemcell: default
  azs: [z1]
  networks:
  - name: services
  lifecycle: errand
  release: logsearch
  jobs:
  - name: smoke_tests
    release: logsearch
    consumes:
      elasticsearch: {from: elasticsearch_master}
